\documentclass[oribibl]{llncs}

% Other packages needed
\usepackage{newfloat,wrapfig}
\usepackage{cite}
\usepackage{chngcntr}
\counterwithout*{figure}{chapter} % make sure figures are numbered right
\DeclareFloatingEnvironment[  % create the Model float
  fileext=los,
  listname=List of Models,
  name=Model,
  placement=tbhp,
  within=section
]{model}
\usepackage{amsmath, amssymb, amsfonts}  % include math packages
\let\doendproof\endproof
\renewcommand\endproof{~\hfill\qed\doendproof} % put square at end of proofs

\usepackage{graphicx,booktabs,multirow,tabu} % include general stuff

% shortcuts etc.
\def\Lmax{{L_{\mathrm{max}}}}
\newcommand{\set}[1]{\{#1\}}

\begin{document}
% Title
\title{A New MIP Model for Parallel-Batch Scheduling with Non-Identical Job Sizes}
\author{Sebastian Kosch \and J. Christopher Beck}
\institute{Department of Mechanical \& Industrial Engineering\\
University of Toronto, Toronto, Ontario M5S 3G8, Canada\\
\email{\set{skosch,jcb}@mie.utoronto.ca}}

\maketitle

\begin{abstract}
  Parallel-batch machine problems arise in numerous manufacturing
  settings from semiconductor manufacturing to printing. They have
  recently been addressed in constraint programming (CP) via the
  combination of the novel \texttt{sequenceEDD} global constraint with
  the existing \texttt{pack} constraint to form the current
  state-of-the-art approach.  In this paper, we present a detailed
  analysis of the problem and derivation of a number of properties
  that are exploited in a novel mixed integer programming (MIP) model
  for the problem. Our empirical results demonstrate that the new
  model is able to outperform the CP model across a range of standard
  benchmark problems. Further investigation shows that the new MIP
  formulation improves on the existing formulation primarily by
  producing a much smaller model and enabling high quality primal
  solutions to be found very quickly.
\end{abstract}

\section{Introduction}

Despite the widespread application of mixed integer programming (MIP)
technology to optimization problems in general and scheduling problems
specifically,\footnote{For example, of the 58 papers published in the
  \emph{Journal of Scheduling} in 2012, 19 use MIP, more than any
  other single approach.} there is a significant body of work that
demonstrates the superiority of constraint programming (CP) and hybrid
approaches for a number of classes of scheduling problems
\cite{Hooker05b,Beck11a,Tran12a,Malapert,Schutt13a}.  While the
superiority is often a result of strong inference techniques embedded
in global constraints \cite{Baptiste00a,Baptiste01a,Vilim09a}, it is sometimes due to problem-specific implementation
in the form of specialized global constraints \cite{Malapert} or
instantiations of decomposition techniques
\cite{Hooker05b,Beck11a,Tran12a}. The flexibility of CP and
decomposition approaches which facilitates such implementation is
undoubtedly positive from the perspective of solving specific problems
better. However, the ability to create problem-specific approaches is
in some ways in opposition to the compositionality and model-and-solve ``holy grail'' of CP
\cite{Freuder97a}: to enable users to model and solve problems without
\emph{implementing} anything new at all.

Our overarching thesis is that, in fact, MIP technology is closer to
this goal than CP, at least in the context of combinatorial optimization
problems. In our investigation of this thesis, we are developing MIP
models for scheduling problems where the current state of the art is
customized CP or hybrid approaches. Heinz et al. \cite{Heinz} showed
that on a class of resource allocation and scheduling problems, a MIP
model could be designed that was competitive with the state-of-the-art
logic-based Benders decomposition. This paper represents a
similar contribution in different scheduling problem: a parallel-batch
processing problem which has previously been attacked by MIP,
branch-and-price \cite{Daste1}, and CP \cite{Malapert} with the latter representing
the state of the art.

We propose a MIP model inspired by the idea of modifying
a canonical feasible solution.
The definition of our objective function in this novel context is not
intuitive until we reason algorithmically about how constraints and
assignments interact -- a strategy often used in designing metaheuristics.
Indeed, we suggest that the analogy between branching
on independent decision variables and making moves between
neighbouring schedules should be explored in more detail for a range of
combinatorial problems.

In the next section we
present the formal problem definition and discuss existing approaches.
In Section \ref{sec:propositions} we prove a number of
propositions that allow us to formally propose a novel MIP model for the problem
in Section \ref{sec:newMIPmodel}.
Section \ref{sec:exp} presents our empirical results, demonstrating
that the performance of the new model is superior to the existing CP
model, both in terms of mean time to find optimal solutions and in terms of solution quality when optimal
solutions could not be found within the time limit.

\section{Background}
\label{sec:background}

Batch machines with limited capacity exist in many manufacturing
settings in forms such as ovens \cite{Lee}, autoclaves \cite{Malapert}, and 
tanks \cite{Grossmann}. In this paper,
we tackle the problem of minimizing the maximum lateness, $\Lmax$,
in a single machine parallel batching problem where each job has an
individual due date and size.

We use the following notation: a set $\mathcal{J}$ of $n$ jobs
is to be assigned to a set of $n$ batches $\mathcal{B} = \{B_1,\dots,B_n\}$.
Batches can hold multiple jobs or remain empty. Each
job $j$ has a processing time, $p_j$, a size, $s_j$,
and a due date, $d_j$. Jobs can be assigned to arbitrary batches, as long as the sum of the sizes of the jobs in a batch does not exceed
the machine capacity, $b$.

The single machine processes one batch at a time. Each batch $B_k$ has a
\textit{batch start date} $S_k$, a \textit{batch processing time},
defined as the longest processing time of all jobs assigned to the
batch, $P_k = \max_{j\in \mathcal{B}_k}(p_j)$, and a \textit{batch completion
  date}, which must fall before the start time of the next batch, $C_k
= S_k + P_k \leq S_{k+1}$.

The lateness of a job $j$, $L_j$, is the completion time of its batch
$C_k$ less its due date $d_j$. The objective function is to minimize the
maximum lateness over all jobs, $\Lmax = \max_{j \in \mathcal{J}}(L_j)$. Since we
are interested in the maximum lateness, only the earliest-due job in
each batch matters and we define it as the \textit{batch due date}
$D_k = \min_{j\in \mathcal{B}_k}(d_j)$.

The problem can be summarized as $1|\textit{p-batch}; b
< n; \textit{non-identical}|\Lmax$ \cite{Daste1, Malapert}, where
$\textit{p-batch};b<n$ represents the resource's parallel-batch nature and its
finite capacity. A version with identical job
sizes was shown to be strongly NP-hard by Brucker et al. \cite{Brucker};
this problem, therefore, is no less difficult.

Figure \ref{fig:intro_tetris} shows a solution to a sample
problem with eight jobs and resource capacity $b = 20$. The last batch
has the maximum lateness $L_5 = C_5 - D_5 = 70 - 39 = 31$.

\begin{figure}[t]
\centering
\includegraphics[width=0.8\textwidth]{tetris.pdf}
\caption{An optimal solution to an example problem with eight jobs (values for
  $s_j$ and $p_j$ are not shown for the two small jobs in batches 1 and 3,
respectively).}
  \label{fig:intro_tetris}
\end{figure}

\subsection{Reference MIP model} The problem is formally defined by MIP
Model \ref{model:malapertmip}, used by Malapert et al. \cite{Malapert} for comparison
with their CP model (see below).

\begin{model}[h]
\begin{alignat}{2}
\mathrm{Min.}\quad & \Lmax && \\
\mathrm{s.t.}\quad &\sum_{k \in \mathcal{B}} x_{jk} = 1 \quad && \forall j \in \mathcal{J}
\label{c:malapp-unique}\\
  &\sum_{j \in \mathcal{J}} s_j x_{jk} \leq b \quad && \forall k \in \mathcal{B}\label{c:malapp-cap}\\
  &p_j x_{jk} \leq P_k \quad && \forall j \in \mathcal{J}, \forall k \in
  K\label{c:malapp-pk}\\
  &C_{k-1} + P_{k} = C_k \quad && \forall k \in \mathcal{B}\label{c:malapp-ck}\\
  &(d_\mathrm{max} - d_j)(1 - x_{jk}) + d_j \geq D_k \quad && \forall j \in \mathcal{J}, \forall
  k \in \mathcal{B}\label{c:malapp-dk}\\
&C_k - D_k \leq \Lmax \quad && \forall k \in \mathcal{B}\label{c:malapp-lmax}\\
  &D_{k-1} \leq D_k \quad && \forall k \in \mathcal{B} \label{c:malapp-edd} \\%[2ex]
  &x_{jk} \in \{0,1\}, C_k \geq 0, P_k \geq 0, D_k \geq 0 \quad && \forall j \in \mathcal{J}, \forall k \in \mathcal{B}  
\end{alignat}
\caption{Reference MIP model}
\label{model:malapertmip}
\end{model}

The decision variables, $x_{jk}$, are binary variables where $x_{jk}=1$
iff job $j$ is assigned to batch $k$. Constraints
\eqref{c:malapp-unique} ensure that each job $j$ is assigned to exactly
one batch $k$. Constraints \eqref{c:malapp-cap} ensure that no batch
exceeds the machine capacity, $b$. Constraints \eqref{c:malapp-pk}
define each batch's processing time, $P_k$, as the maximum processing time
of the jobs $j$ assigned to it. Constraints \eqref{c:malapp-dk} implement the
definition of $D_k$ while ensuring that for empty batches $k$, $D_k = d_\text{max}$.
Constraints \eqref{c:malapp-ck} define
each batch's completion time, $C_k$, as that of the previous batch, plus
the batch's processing time. Constraints \eqref{c:malapp-lmax} define
the objective value $\Lmax$. Constraints \eqref{c:malapp-edd} sort the
batches by due date, based on a well-known dominance rule: there exists
an optimal solution with batches scheduled in earliest-due-date-first
order (EDD). This stems from the fact that if all jobs are already 
assigned, the problem reduces to a polynomial-time solvable single machine
problem ($1|D_k|\Lmax$) \cite{Pinedo03}.

\subsection{Previous Work}

Malapert et al. \cite{Malapert} present a CP formulation of the problem
(see Model \ref{model:malapertcp}) which relies on two
global constraints: \texttt{pack} \cite{ShawPacking}, which constrains the
job-to-batch assignments such that no capacity limits are violated,
and \texttt{sequenceEDD}, which enforces the EDD order over the batches. The
implementation of the latter constraint is the main contribution of
the paper and is primarily responsible for the strong performance. \texttt{sequenceEDD}
includes a set of pruning rules that update the lower and upper bounds on
$\Lmax$ and on the number of batches every time the constraint
is triggered by a job-batch assignment. Based on these bounds, other
assignments are then eliminated from the set of feasible assignments.

\begin{model}
  \label{model:malapertcp}
  \begin{alignat}{2}
    \mathrm{Min.}\quad & \Lmax &&  \\
    \mathrm{s.t.}\quad \label{c:mcpmax} & \mathtt{maxOfASet}(P_k, B_k, [p_j]_k,
    0) && \quad \forall k \in \mathcal{B} \\
    \label{c:mcpmin} & \mathtt{minOfASet}(D_k, B_k, [d_j]_k, d_\mathrm{max}) &&
    \quad \forall k \in \mathcal{B} \\
    \label{c:mcppack} & \mathtt{pack}(B_k, A_j, S_k, M, s_j) && \\
    \label{c:mcpseq} & \mathtt{sequenceEDD}(B_k, D_k, P_k, M, \Lmax) && 
\end{alignat}
  \caption{CP model proposed by Malapert et al.}
\end{model}

Constraints \eqref{c:mcpmax} define $P_k$ as the maximum of the set
of processing times $[p_j]_k$ belonging to the jobs assigned to
batch $B_k$, with a minimum value of 0 (note that the notation is
adapted from Malapert et al. to match that in this paper). Constraints
\eqref{c:mcpmin} define $D_k$ as the minimum of the due dates $[d_j]_k$
associated with the set of jobs assigned to the batch $B_k$, with a
maximum of $d_\mathrm{max}$, the largest due date among all given jobs.
Constraint \eqref{c:mcppack} implements the limited batch capacity $b$.
It uses propagation rules incorporating knapsack-based reasoning, as
well as a dynamic lower bound on the number of non-empty batches $M$
\cite{Malapert,ShawPacking}. Note that this constraint handles the
channeling between the set of jobs assigned to batch $B_k$, and the
assigned batch index $A_j$ for each job $j$. The limited capacity is
enforced by setting the domain of the batch loads, $S_k$, to $[0, b]$.
Constraint \eqref{c:mcpseq} ensures that the objective value $\Lmax$ is
equal to the maximum lateness of the batches scheduled according to the
EDD rule.

The problem has also been addressed with a detailed branch-and-price
algorithm \cite{Daste1}, which is described in \cite{Malapert} as
follows: each batch is a column in the column generation master
problem. A solution of the master problem is a feasible sequence of
batches. The objective of the subproblem is to find a batch which
improves the current solution of the master problem. Malapert et al.
\cite{Malapert} showed that their CP model, was significantly faster
than the branch-and-price algorithm which itself was more efficient 
than the reference MIP model. 

Other authors have examined similar problems: Azizoglu \& Webster
\cite{Azizoglu} provide an exact method and a heuristic for the same
problem, but minimize makespan ($C_\mathrm{max}$) instead of $\Lmax$,
similar to the work by Dupont and Dhaenens-Flipo \cite{Dupont}.
Exact methods have been proposed for multi-agent variants
with different objective functions by Sabouni and Jolai \cite{Sabouni},
for makespan minimization on single batch machines by Kashan et al.
\cite{Kashan}, and for makespan minimization on parallel batch machines
with different release dates \cite{Ozturk}. An
extensive review of MIP models in batch processing is given
by Grossmann \cite{Grossmann}. 

\section{Exploiting the Problem Structure}
\label{sec:propositions}

In this section, we make a series of observations about the
parallel-batch scheduling problem that allow us to develop a novel MIP
formulation.

\subsection{The single-EDD schedule and assigning jobs to earlier batches}
We can exploit the EDD rule to eliminate $\frac{1}{2}(n^2 - n)$ of the
$n^2$ potential job-batch assignments a priori.

We first re-index all jobs in non-decreasing due date (and in
non-decreasing processing time in case of a tie).
%, which can be done in $\mathcal{O}(n \log n)$ time. 
For the remainder of this paper, consider
all jobs to be indexed in this way. We then define
the \textit{single-EDD} schedule, in which each batch $B_k$ contains the
\textit{single} job $j$ matching its index (i.e., $x_{jk}=1$ iff
$j=k$), such that EDD is always satisfied. We refer to $j$ as the \textit{host
job} of batch $B_k$, while other jobs assigned to $B_k$, if any, are \textit{guest jobs}.

\begin{lemma}
  \label{lemma:emptyorsame}
Consider a schedule $S$ in which $B_k$ is the earliest-scheduled batch such that its
host job $j$ is assigned to a later-scheduled batch $B_{k+m}$. In this schedule,
$B_k$ is either empty or $D_k = d_j$ (even though $j \notin B_k$).
\end{lemma}
\begin{proof}
If $B_k$ is non-empty, $D_k \geq d_j$: since $B_k$ is defined as
the earliest scheduled batch whose host job is scheduled later, $B_k$ cannot
host jobs due before $d_j$. But if $D_k > d_j$ then EDD is violated, as $D_{k+m}
= d_j$. Thus, $B_k$ is empty, or $D_k = d_j$ (due to other jobs with due date $d_j$ assigned to
$B_k$).
\end{proof}

\begin{proposition} \label{prop:movebackonly}
There exists an optimal solution in which job $j$ is assigned to batch
$B_k \; j \leq k$.
\end{proposition}

% Before giving a proof, we prove the following lemma.

% Schedule $S$ clearly violates the constraint given in Proposition
% \ref{prop:movebackonly}. We now prove the proposition by showing that $S$ is
% not uniquely optimal.

\begin{proof}
  Consider again schedule $S$. Since $D_{k+m} = d_j$, EDD requires that no batch $B_q,
  k\leq q<k+m$, is due after $d_j$. By Lemma \ref{lemma:emptyorsame}, we only
  need to consider the following two cases:

  \begin{enumerate}
    \item{$B_k$ is empty, so $P_k = 0$. Since EDD is not violated, we
    know that $D_q = d_j\;\forall\;B_q, k \leq q \leq k+m$. We can assign all jobs from $B_{k+m}$ into $B_k$, such that
    $P_{k+m} = 0$. $\Lmax$ will stay constant, as the completion time of
    the last-scheduled of all batches due at $d_j$ does not change.}
    \item{$B_k$ is non-empty and due at $D_k = d_j$ (although $j \notin B_k$), due
        to at least one job $g$ from a later-scheduled batch for which
        $d_g = d_j$, which is assigned to $B_k$. In this case, since $D_k
        = d_j = D_{k+m}$ and since EDD is not violated, \textit{all} batches $B_q$
        where $k \leq q \leq k+m$ must be due at $d_j$. But then we can re-order
        these batches such that their respective earliest-due jobs are once
        again assigned to their single-EDD indices. The jobs in $B_{k+m}$
        (including $j$) will be assigned to $B_k$ as a result. $\Lmax$
    is not affected by this re-assignment, as the completion time of the
    last-scheduled batch due
  at $d_j$ does not change.}
  \end{enumerate} \end{proof}

We thus introduce the following constraint to exclude solutions
in which jobs are assigned to later batches than their single-EDD
batches.
\begin{alignat}{2}
  & x_{jk} = 0 \quad && \forall \{j \in \mathcal{J}, k \in \mathcal{B} | j < k\} \label{eq:mipnopp}
\end{alignat}

We can also show that in every non-empty batch $B_k$,
the earliest-due job $j$ must be the host job.
%(such that $j = k$). 
This means that when batch $B_k$'s host job is assigned to an
earlier batch, no other jobs can be assigned to $B_k$; a batch
that is \textit{host-less} must be empty. This requirement rests on the
following proposition.

\begin{proposition}\label{prop:nohostless}
There exists an optimal solution that has no host-less, non-empty batches.
\end{proposition}
\begin{proof}
Consider an EDD-ordered schedule in which batch $B_j$ is the
last-scheduled batch which is host-less but non-empty: instead of its host job, only a set $G$ of later-due guest jobs is assigned
to $B_j$ ($j \notin G$).

The earliest-due job $g \in G$ must have the same due date as batch
$B_{j+1}$: if it is due later, EDD is violated; if it is due earlier,
$G$ is not a set of later-due guest jobs. Job $g$'s own host batch $B_g$
(which is host-less) cannot itself be due later than $d_g = D_{j+1}$ --
this would require $B_g$ to have guest jobs from later batches, but we
defined $B_k$ as the last batch with this property -- therefore, $D_q =
D_{j+1}$ for all batches $B_q, j \leq q \leq g$.

Then we can re-assign the guest jobs $G$ from $B_j$ into $B_g$,
such that $g$ is again host job in its own single-EDD batch. This
re-assignment has no impact on $\Lmax$ since it makes $P_j = 0$,
resulting in the same completion time of the set of all batches with
batch due date $D = D_{j+1}$.
\end{proof}

The above proposition translates to the following constraint:
\begin{alignat}{2}
  && x_{kk} \geq x_{jk} \quad & \forall\{j \in \mathcal{J}, k \in \mathcal{B} |
j> k\}
\end{alignat}

This observation allows us to define the due date of \emph{all} batches
to be the due date of their respective host jobs: $D_k = d_j\,\forall\{j
\in \mathcal{J}, k \in \mathcal{B}|j=k\}$. This rule holds
even for empty batches $B_k$: $P_k = 0$, so $C_k = C_{k-1}$; but
$D_{k-1} \leq D_k$ due to this rule, so $L_{k-1} \geq L_k$ and thus
$L_k$ has no impact on $\Lmax$.

\subsection{Reformulating the objective function}
\label{sec:moves}

We can formulate each batch's lateness, $L_k$, as its 
lateness in the single-EDD schedule, modified by the assignment of jobs into and
out of batches $B_h, h \leq k$. 

We first define $\mathcal{B}^\star \subseteq \mathcal{B}$ as the set of batches
$B_k$ which, given any EDD schedule, are the last-scheduled among all batches
with due date $D_k$, since we can make the following observation.
\begin{proposition}
Given a set of batches with equal due date in a schedule, we only need to 
consider the lateness of the one scheduled last.
\end{proposition}
\begin{proof}
  In an EDD ordering, the lateness of the batch scheduled last is greater
  than (or equal to, in the case of an empty batch) the lateness values
  of all other batches sharing its due date as it has the latest completion
  date.
\end{proof}
This fact allows us to reduce the number of constraints defining $\Lmax$, as
we only need to consider batches $\mathcal{B}^\star$ as potential candidates for
$\Lmax$.

To simplify the following exposition, we define the term
\textit{move} as the re-assignment of a job $j$ from its single-EDD
batch $B_k$ to an earlier batch $B_h, h < k$, such that $x_{jk}=0$ and $x_{jh}=1$ and $j$
is a guest job in $B_h$.
Any schedule can thus be understood as a set of such moves, executed in arbitrary
order starting from the single-EDD schedule. To define the objective function,
we consider the change in $\Lmax$ associated with individual moves.
%, going
%from one schedule to another, instead of reasoning about the $\Lmax$ value of an entire schedule at once.

Consider any EDD
schedule, such as the one in Figure \ref{fig:movebasedmip}(a). Moving
a job $j$ from its single-EDD batch $B_{k=j}$ into an earlier batch
$B_e$ has the following effect:

\begin{itemize}
\item the lateness of all batches $B_i, i \geq k$ is reduced by $p_j$(Figure \ref{fig:movebasedmip}(b)),
\item the lateness of all batches $B_h, h \geq e$ is increased by
$\max(0,p_j - P_e)$, where $P_e$ is the processing time of batch $B_e$
before $j$ is moved into it (Figure \ref{fig:movebasedmip}(c)).
\end{itemize}

\begin{figure}[th]
\centering
\includegraphics[width=0.8\textwidth]{movebasedmip.pdf}
\caption{Moving a job in a single-EDD schedule. Job 5 (marked
``$p_5 = 10$'') is moved from its single-EDD batch 5 into the earlier batch 3.
This changes the lateness of job 7 (marked $\star$) from $L_\mathrm{7,single}$
to $L_\mathrm{7,single} - 10 + 6 = L_\mathrm{7,single} - 4$.}
  \label{fig:movebasedmip}
\end{figure}

In any batch, only the host job's lateness is relevant to $\Lmax$.
In other words, the lateness of batch $B_k$ equals the lateness of
job $j=k$, unless the job was moved into an earlier batch (in which
case $P_k = 0$ due to Proposition \ref{prop:nohostless} and $L_k = L_{k-1}$). Therefore, we can understand
the lateness of batch $B_k$ as its lateness in the single-EDD schedule, written as
$L_{k,\mathrm{single}}$, modified by the summed effect that all moves of
other jobs into and out of batches $h \leq k$ have on the completion time
of $B_k$:
\begin{alignat}{2}
  \label{c:lmaxc} & L_k = L_{k,\mathrm{single}} + \sum_{h\leq k} \underbrace{P'_h - p_h(2 -
x_{hh})}_{T_h} \quad && \forall k \in \mathcal{B}^\star\\
  \label{c:pkpj} & P'_k \geq p_j x_{jk} \quad && \forall \{j \in \mathcal{J}, k \in \mathcal{B} | j \geq k\} \\
  \label{c:pkmin} & P'_k \geq p_j \quad && \forall \{j \in \mathcal{J}, k \in \mathcal{B} | j = k\}
\end{alignat}
where $P'_k = \max(P_k, p_k) \forall k \in \mathcal{B}$ as defined in
constraints \eqref{c:pkpj} and \eqref{c:pkmin}.

  For every batch $B_k \in \mathcal{B}^\star$, consider the possible scenarios for all batches
$B_h, h \leq k$:
\begin{itemize}
  \item{Batch $B_h$ holds its host job. Then $x_{hh}=1$ and the summand $T_h$ evaluates
      to $P'_h - p_h$. If $B_h$ has guest jobs, then $P'_h - p_h > 0$ if any of
      them are longer than the host job; if all guests are shorter, $P'_h=p_h$
    and $T_h = 0$.}
  \item{Batch $B_h$ is hostless and thus empty. We require $T_h = -p_h$ in
      accordance with Figure \ref{fig:movebasedmip}(b). To achieve this, we
      state in constraints \eqref{c:pkmin} that $P'_h$ never drop below the
      length of its host job, even when $P_h=0$. With this in effect, the
      minimization objective enforces $P'_h = p_h$ and $T_h = P'_h - 2p_h =
    -p_h$.}
\end{itemize}
Thus, we add to $L_k$ the increase in processing time due
to guests, $\max(0, P'_h-p_h)$, for every non-empty batch $B_h$. We
subtract from $L_k$ the host job processing time $p_h$ for every empty
batch $B_h$. This is congruent with Figure \ref{fig:movebasedmip} above.

% Note that the $P'_k$ variables used here are not the same as the
% physically meaningful $P_k$ due to constraints \eqref{c:pkmin}, which is
% why we distinguish them with a prime mark.


The net sum of these additions and subtractions to and from
$L_{k,\mathrm{single}}$ adjusts the lateness of batch $k$ to its correct value
given the values of $x_{jk}$.


\begin{proposition}
  Constraints \eqref{c:lmaxc}--\eqref{c:pkmin} correctly define $L_k$ for each batch $B_k$.
\end{proposition}
\begin{proof}
By induction on $k$, our base case is the lateness of the first batch ($k=1$). It is clear that the lateness of $B_k$ is equal to its single-EDD lateness,
plus $\max(P_1 - p_1, 0)$ since guest jobs may cause $P_1 > p_1$:
\begin{equation}
  \label{eq:ind1}
  L_1 = L_{1,\mathrm{single}} + \underbrace{P'_1 -
  p_1(2-x_{11})}_{=\max(P_1-p_1,0)}.
\end{equation}
Our induction hypothesis is that the proposition holds for any batch $B_k$:
\begin{equation}
  \label{eq:indhyp}
  L_k = L_{k,\mathrm{single}} + \sum_{h \leq k} P'_h - p_h(2-x_{hh})
\end{equation}
To show how an expression for $L_{k+1}$ then follows,
we relate $L_{k+1}$ to $L_k$:
\begin{equation}
\label{eq:k1k}
  L_{k+1} = L_k + \underbrace{P_{k+1}}_{C_{k+1}-C_k} - \underbrace{(d_{k+1} -
  d_k)}_{D_{k+1}-D_k}
\end{equation}
The difference $L_{k+1} - L_k$ can also be written in terms of single-EDD
lateness values and processing time adjustments due to guests or host-lessness,
all of which are expressed in known terms:
\begin{equation}
  \label{eq:ind3}
  P_{k+1} - (d_{k+1} - d_k) = L_{k+1,\mathrm{single}} - L_{k,\mathrm{single}}+
\begin{cases}\max(P_{k+1}-p_{k+1},0)&x_{k+1,k+1}=1\\-p_{k+1}&x_{k+1,k+1}=0\end{cases}.
\end{equation}
The conditional expression is equivalent to $P'_{k+1} -
p_{k+1}(2-x_{k+1, k+1})$. We can now rewrite \eqref{eq:k1k} for $L_{k+1}$ and arrive at
\begin{align}
  \label{eq:ind4}
   L_{k+1} =& \left[L_{k,\mathrm{single}} + \sum_{h \leq k} P'_h
- p_h(2-x_{hh})\right]  \nonumber \\ &+ L_{k+1,\mathrm{single}} - L_{k,\mathrm{single}}+ P'_{k+1} -
p_{k+1}(2-x_{k+1, k+1}),
\end{align}
which, after cancelling out $L_{k,\mathrm{single}}$ terms, becomes
\begin{align}
  \label{eq:indfin}
 L_{k+1} = L_{k+1,\mathrm{single}} + \sum_{h \leq k+1} P'_h - p_h(2-x_{hh})
\end{align}
and agrees with \eqref{eq:indhyp}. Since \eqref{eq:indfin} follows from
\eqref{eq:indhyp}, and the latter is true for the base case of $k = 1$,
\eqref{c:lmaxc} is true for all $k$.
\end{proof}

Note also that in the case of an empty batch $B_k \in
\mathcal{B}^\star$, if $B_{k-1} \notin \mathcal{B}^\star$,
$d_k = d_{k-1}$ and $x_{kk}=0$, so $L_k = L_{k-1}$ as evident from
\eqref{eq:ind4}; if $B_{k-1} \in \mathcal{B}^\star$, $d_k > d_{k-1}$,
and thus $L_k < L_{k-1}$. as $d_k = d_{k-1}$ and $x_{kk} = 0$ if $B_k$
is empty.

\subsection{Additional lazy constraints}
\label{sec:lazyconstraints}
\textit{Lazy constraints} \cite{cplexmanual} are also used in the model. Lazy
constraints are simple constraints based on the specific problem. Large numbers
of them are generated prior to solving, but they are
not immediately used in the model. Instead, they are checked against
whenever an integral solution is found, and only those that are violated
are added to the LP model. In practice, only few of the lazy constraints
are used in the solution process. Nevertheless, they can noticeably
improve solving time in some cases.

\subsubsection{Symmetry-breaking rule}
This rule creates an explicit, arbitrary preference for certain solutions.
Consider two schedules $S_1$ and
$S_2$. Both schedules contain batches $B_h$ and $B_k$, both of which
are holding their respective host jobs only. Two jobs $j$ and $i$ are now
assigned as the only guests to the two batches; furthermore $\max(p_i, p_j) \leq
\min(p_h, p_k)$, $\max(s_h, s_k) + \max(s_j, s_i) \leq b$ and
$\min(d_j, d_i) \geq \max(d_h, d_k)$. If $j \in
B_h$ and $i \in B_k$ in schedule $S_1$ and vice versa in
$S_2$, then the constraint renders $S_2$ infeasible.

\begin{alignat}{2}
  & \begin{gathered} 2 (  4 - x_{hh} - x_{kk} - x_{jh} - x_{jk} -
x_{ih} - x_{ik}\hfill \\+ \sum_{\substack{{g}\\{g \neq j}\\{g \neq
i}}} (x_{gh} + x_{gk}) ) \geq x_{jk} + x_{ih} \end{gathered}
\quad && \begin{gathered} \forall\{ j, i \in \mathcal{J}, \\ h, k \in
\mathcal{B} \\|\; h < k <
j < i \land \\ [p_q \leq p_r \land b - s_r \geq s_q\\ \forall q \in
\{j,i\}, \\ \forall r
\in \{h,k\}] \} \end{gathered}
\end{alignat}

The left-hand side of the equation evaluates to zero exactly when the above
conditions are met, which in turn disallows the assignment given on the right.
For all other job/batch pairings, the left side evaluates to at least two, which
places no constraint on the right hand side at all.

This kind of symmetry-breaking rule can be extended to 
$m > 2$ batches, with the number of constraints growing combinatorially with $m$. Since it takes
a constant but appreciable time to generate these constraints prior to solving,
we have in our trials kept to the simplest variant shown here, and limited their
use to problem instances with $n \geq 50$ jobs.

\subsubsection{Dominance rule on required assignments}
A schedule is not uniquely optimal if a job $j$ is left in its single-EDD batch
although there is capacity for it in an earlier batch. This constraint can
be expressed logically as: if a job $j$ can be safely assigned to $B_k$ without
violating the capacity constraint, then $j$ must be moved somewhere, or
$B_k$ must be empty (or both). 

The left side of the above \textit{if-then} statement is written as $(1.0 + b -
s_j - \sum_{\substack{{i = k}\\{i \neq j}}}^{n_j} s_i x_{ik}) / b$, which
evaluates to 1.0 or greater iff $s_k$ plus the sizes of guest jobs in $k$ sum to
less than $b - s_j$. The constraint is written as follows:
\begin{alignat}{2}
&2 - x_{jj} - x_{kk} \geq \left(1.0 + b - s_j -
\sum_{\substack{{i = k}\\{i \neq j}}}^{n_j} s_i
x_{ik}\right) / b \quad && \begin{gathered} \forall \{ j \in \mathcal{J}, k \in \mathcal{B}\\| j > k 
\land p_k \geq p_j \\ \land s_k + s_j \leq b\}\end{gathered}
\end{alignat}\\

As with the rule above, we have found that only more difficult problems with $n
\geq 50$ benefit from these constraints.

\section{A New MIP Model}
\label{sec:newMIPmodel}

The full novel MIP model we are proposing is defined in Model \ref{mod:movebackmip}.

\begin{model}
\begin{alignat}{2}
\mathrm{Min.}\quad & \Lmax && \\
\mathrm{s.t.}\quad & \label{mbm:eq7}\sum_{k} x_{jk} = 1 \quad && \forall j \in \mathcal{J} \\
& \label{mbm:eq6}\sum_{j} s_j x_{jk} \leq b \quad && \forall k \in \mathcal{B} \\
&\label{mbm:eq3} P'_k \geq p_j x_{jk} \quad && \forall \{j \in \mathcal{J}, k \in \mathcal{B} | j \geq k\} \\
&\label{mbm:eq10} P'_k \geq p_j \quad && \forall \{j \in \mathcal{J}, k \in \mathcal{B} | j = k\} \\
&\label{mbm:eq5} x_{kk} \geq x_{jk} \quad && \forall \{j \in \mathcal{J}, k \in \mathcal{B} | j > k\} \\
&\label{mbm:eq4} \Lmax \geq L_{k,\mathrm{single}} + \sum_{h\leq k} P'_h - p_h(2 -
x_{hh}) \quad && \forall k \in \mathcal{B}^\star \\
  \label{mbm:eq1} & x_{jk} = 0 \quad && \forall \{j \in \mathcal{J}, k \in \mathcal{B} | j < k\}
  \\[2ex]
  (*)\quad \label{mbm:eq8}   & \begin{gathered} 2 (  4 - x_{hh} - x_{kk} - x_{jh} - x_{jk} -
x_{ih} - x_{ik}\hfill \\+ \sum_{\substack{{g}\\{g \neq j}\\{g \neq
i}}} (x_{gh} + x_{gk}) ) \geq x_{jk} + x_{ih} \end{gathered}
\quad && \begin{gathered} \forall\{ j, i \in \mathcal{J}, \\ h, k \in
\mathcal{B} \\|\; h < k <
j < i \land \\ [p_q \leq p_r \land b - s_r \geq s_q\\ \forall q \in
\{j,i\}, \\ \forall r
\in \{h,k\}] \} \end{gathered}
 \\[2ex]
(*)\quad &  \label{mbm:eq11}2 - x_{jj} - x_{kk} \geq \left(1.0 + b - s_j -
\sum_{\substack{{i = k}\\{i \neq j}}}^{n_j} s_i
x_{ik}\right) / b \quad && \begin{gathered} \forall \{j \in \mathcal{J},k \in \mathcal{B} \\| j > k 
\land p_k \geq p_j \\ \land s_k + s_j \leq b\}\end{gathered}
\end{alignat}
\caption{The new MIP model. Constraints marked $(*)$ are lazy constraints.}
\label{mod:movebackmip}
\end{model}

Constraints \eqref{mbm:eq7} and \eqref{mbm:eq6} are uniqueness and
capacity constraints: batches have to remain within capacity $b$, and every
job can only occupy one batch. Constraints \eqref{mbm:eq3} and \eqref{mbm:eq10} define the value of
$P'_k$ for every batch $k$ as the longest $p$ of all jobs in $k$, but
at least $p_k$. This is required in \eqref{mbm:eq4}, which follows the
explanation above. Constraints \eqref{mbm:eq5} ensure that no job is moved into a host-less batch,
i.e. in order to move job $j$ into batch $k$ ($x_{jk} = 1$), job $k$ must still
be in batch $k$ ($x_{kk} = 1$). Constraints \eqref{mbm:eq1} implement the requirement that jobs are only moved
into earlier batches. Constraints \eqref{mbm:eq8} and \eqref{mbm:eq11} implement the additional lazy
constraints described above.

\section{Empirical comparison}
\label{sec:exp}

We empirically compared the performance of the CP model by Malapert et al. and
Model \ref{mod:movebackmip}. Both models were run on 120
benchmark instances as in Malapert et al. (i.e. 40 instances of each $n_j = \{20,
50, 75\}$). The benchmarks are generated as specified by Daste \cite{Daste1}, with a
capacity of $b = 10$ and values for $p_j$, $s_j$ and $d_j$ distributed as follows: $p_j = U[1, 99]$,
$s_j = U[1, 10]$, and $d_j = U[0, 0.1] \cdot \tilde{C}_\text{max} + U[1, 3] \cdot p_j$.
% \begin{align}
% p_j &= U[1, 99] \\
% s_j &= U[1, 10] \\
% d_j &= U[0, 0.1] \cdot \tilde{C}_\text{max} + U[1, 3] \cdot p_j
% \end{align}
$U[a, b]$ is a uniform distribution between $a$ and $b$, and
$\tilde{C}_\text{max} = \frac{1}{bn} \cdot \left( \sum_{j=1}^{n_j} s_j \cdot \sum_{j=1}^{n_j}
p_j \right)$ is an approximation of the time required to process
all jobs.

The MIP benchmarks were run using \textsc{cplex} 12.5 \cite{cplex} on an Intel
i7 Q740 CPU (1.73 GHz) and 8 GB RAM in single-thread mode, with \textsc{cplex}
parameters \texttt{Probe = Aggressive} and \texttt{MIPEmphasis = Optimality}
(the latter for $n=20$ only). The CP was implemented using the Choco solver library \cite{choco} and run on the same
machine using the same problem instances.\footnote{The authors would like to extend a warm
  thank-you to Arnaud Malapert for both providing his code and helping us run
it.}
Solving was aborted after a time of 3600 seconds (1 hour).

The reference MIP model solves fewer than a third of the instances
within the time limit. The branch-and-price model \cite{Daste1} is reported to 
perform considerably worse than CP \cite{Malapert}. Therefore, neither of the two is
included here.

\subsection{Results}
The overview in Table \ref{table:results} shows aggregated results that
demonstrate the performance and robustness of our new model.


\begin{table}[t]
\small
\noindent\begin{tabu} to \linewidth {l l X[r] X[r] X[r] X[r] X[r]}
  \toprule
  \multirow{2}{*}{$n_j$}& \multirow{2}{*}{optimal soln. found by} &
  \multirow{2}{*}{instances} &
\multicolumn{2}{r}{solving time [s]} & \multicolumn{2}{r}{
absolute gap} \\
   & & & CP & MIP & CP & MIP \\
  \toprule
  20\;\; & both models & 40/40 & 0.42 & 0.04 & 0 & 0 \\
  \midrule
  50 & both models & 40/40 & 5.67 & 4.16 & 0 & 0 \\
  \midrule
  \multirow{4}{*}{75} & both models & 22/40 & 49.30 & 52.88
  & 0 & 0 \\
  & CP model only & 0/40 & --- & --- & --- & --- \\
  & MIP model only & 13/40 & $>3600$ & 139.86 & 323.46 & 0
  \\
  & neither model & 5/40 & $>3600$ & $>3600$ & 310.40 & 25.00 \\
  \bottomrule
\end{tabu}
\vspace{0.3em}
\caption{Summary of empirical results. Values are geometric means for solving
  time and arithmetic means for absolute gaps. No relative gaps are given
  due to negative lower bounds.}
\label{table:results}
\end{table}
%\normalsize

\begin{table}[t]
\small
  \noindent\begin{tabu} to \linewidth {l X[r] X[r] X[r] X[r] X[r] X[r]}
  \toprule
  \multirow{2}{*}{Mean (120 instances)} & \multicolumn{2}{r}{Reference MIP} &
  \multicolumn{2}{r}{Improved MIP} & \multicolumn{2}{c}{\quad\; Reduction}\\
    & Rows & Cols & Rows & Cols & Rows & Cols \\
  \midrule
  Before presolve & 7415.14 & 3033.81 & 4291.48 & 2882.76 & $-42.1\%$ & $-5.0\%$ \\
  After presolve & 2209.34 & 1513.06 & 754.57  & 687.13 & $-65.8\%$ & $-54.6\%$ \\
  \midrule
  Reduction & $-70.2\%$ & $-50.1\%$ & $-82.4\%$ & $-76.1\%$ & --- & --- \\
  \bottomrule
\end{tabu}
\vspace{0.3em}
\caption{Average numbers of variables and constraints in
  reference and improved MIP models before and after processing by
  \textsc{cplex}'s presolve routines.}
\label{table:beforeafterpresolve}
\end{table}


As shown in Figure \ref{fig:scattercomp}, our MIP model performs better overall on
instances with $n_j = 20$ and $n_j = 75$, while MIP and CP perform similarly
well on intermediate problems ($n_j = 50$).

Wherever an optimal solution was not found,
the improved MIP model achieved a significantly better solution quality: 
out of the 40 instances with $n_j = 75$, 22 were solved to optimality by both CP
and MIP, 13 were solved to optimality by the MIP only, and 5
were solved by neither model within an hour.  A comparison of solution quality where no optimal schedule was
found confirms the robustness of the improved MIP model: as Figure
\ref{fig:gapcomp} illustrates, the gap (UB($\Lmax)-$LB($\Lmax$)) is
consistently larger in the CP model. This means that even with very difficult
problems, our model will often give near-optimal solutions more quickly
than Malapert et al.'s CP model.

We further found that the lazy constraints introduced in Section
\ref{sec:lazyconstraints} did not yield \emph{consistent} benefits across
problems; in fact,
they doubled and tripled solving times for some instances. On average, however,
adding the lazy constraints resulted in a speed gain on the order of about 10\%,
especially for larger problems ($n \geq 50$).

\begin{figure}[t]
\begin{minipage}[t]{.475\textwidth}
\includegraphics[width=\textwidth]{scattercomp.pdf}
\caption{Performance comparison over 120 instances, each represented by one data
point. Horizontal/vertical coordinates correspond to solving time by CP model
and improved MIP model, respectively. Note that 18 instances were not solved to
optimality within an hour by either the CP model or both models.}
\label{fig:scattercomp}
%\includegraphics[width=2in]{scattercomp.pdf}
%Some text.
\end{minipage} %
\hfill
\begin{minipage}[t]{.475\textwidth}
\centering
\includegraphics[width=\textwidth]{gapcomp.pdf}
\caption{Comparison of solution quality for the 18 instances that were not
solved to optimality within an hour by either the CP model or both models. White bars represent
the LB-UB gap achieved by the CP model, black bars the LB-UB gap achieved by the
improved MIP model (straight line where solved to optimality).}
\label{fig:gapcomp}
%\includegraphics[width=2in]{elephant}
%Some more text.
\end{minipage}
\end{figure}


\section{Discussion}
\label{sec:discussion}

%\subsubsection{Understanding the performance differences}

One likely contribution to the new model's performance is its reduced
size compared to the reference MIP model: while the reference model
required $3n^2 + 8n$ constraints over $n^2 + 3n$ variables, our
model uses fewer than $2.5n^2 + 2.5n$ constraints over $n^2 + n$
variables.\footnote{The word ``fewer'' here arises from the problem-specific
cardinality of $\mathcal{B}^\star$.} In addition, \textsc{cplex}'s
presolve methods are more effective on our model (see Table
\ref{table:beforeafterpresolve}), reducing its size further.

Figure \ref{fig:lbubcomp} shows the evolution of bounds (i.e. best feasible
solutions and tightest LP solutions at the nodes) for the three
models over the first few seconds. It is based on the logs for
the 40 instances with $n = 75$, which contain only irregular timestamps.
%Yet even such approximate data demonstrates two interesting points.
While the new MIP model is better than the reference model on both the lower
and upper bounds, the largest gain appears to derive from the latter,
indicating that unlike what is commonly observed, the improved MIP model
benefits not from a tighter relaxation but from being more amenable to
the solver's primal heuristics.

\begin{figure} %{0.5\textwidth}
\centering
\includegraphics[height=0.3\textheight]{lbubcomp.pdf}
\caption{Evolution of upper and lower bounds.
Left cutoffs indicate the approximate mean time at which the
respective bound was first found.}
\label{fig:lbubcomp}
\end{figure}

% \begin{wrapfigure}{l}{0.5\textwidth}
% \centering
% \includegraphics[height=0.3\textheight]{lbubcomp.pdf}
% \caption{Evolution of upper and lower bounds.
% Left cutoffs indicate the approximate mean time at which the
% respective bound was first found.}
% \label{fig:lbubcomp}
% \end{wrapfigure}


The upper bound for the improved MIP model matches that of the CP model.
CP is often able to find high quality solutions faster than MIP. However, the improved model removes that
advantage on our test problems.

\subsubsection{Making moves in MIP modeling}

One of the novelties of the new MIP model, as well as much of its
inspiration, is the consideration of \textit{moves} from the canonical
single-EDD solution. The effects of the assignment variables on the
objective function can be considered discretely, allowing us to reason
about them algorithmically even though they constitute a
declarative model.  The concept of moves is common in local
search techniques including Large Neighbourhood Search (LNS) \cite{shaw}
where moves correspond to the removal and re-insertion of jobs from
and into the schedule, similar to our reasoning in Section
\ref{sec:moves}.  

This line of reasoning presents several interesting directions for future work including (i) using the idea of moves from a canonical solution to develop MIP and CP models for other optimization problems and (ii) the derivation of dominance rules to restrict LNS moves on large problems and thereby expand the size of the neighbourhoods that can be explored.

% Analogous to the notion of ``neighbourhood'' is the
% set of schedules than can be reached via feasible moves, starting from
% any other schedule. We can then easily represent the objective
% function as a sum of changes from some canonical solution. Such
% models, while non-standard, may provide substantial insight into
% problem structure that can be exploited in a MIP (or CP) formulation.

\subsubsection{Models vs. global constraints}

Our results show that the novel MIP model is an improvement over
previous approaches, demonstrating that at least in this case, the
performance of a specialized global constraint implementation can
indeed be matched and exceeded by a comparatively simple mathematical
formulation. Mathematical models have the general benefit of being more readily
understandable, straightforward to implement and reasonably easy to
adapt to new, similar problems.

A global constraint is most valuable when it is the encapsulation of a
problem structure that occurs across a number of interesting problem
types. It can then be used far beyond its original context. However,
with the flexibility to define arbitrary inference operations comes the
temptation to develop problem-specific global constraints and to
trade the ideal of re-usability for problem solving power. We believe
that the collection of global constraints in CP is mature enough that
most problem-specific efforts are now best placed on exploring novel ways
to exploit problem structure using existing global constraints. To this
end, one of our current research efforts is the development of a CP
model exploiting the propositions proved in this paper without needing novel global constraints.

%%%%%%%%%%%
%A global constraint is most valuable when it is the
%encapsulation of a problem structure that occurs across a number of
%interesting problem types. It can then be used far beyond its original
%context. However, the flexibility to define an arbitrary inference
%operation on variable domains comes with the temptation to develop
%problem-specific global constraints, trading the re-use and wide
%applicability for problem solving power. From an application engineering
%perspective, such a trade-off may be reasonable. However, such work
%does not further CP as a \emph{general} modeling and solving framework.
%To that end, we believe that the collection of global constraints
%has reached a level of maturity that problem-specific effort is
%better placed on efforts of problem modeling, using existing global
%constraints, that exploit structure such as demonstrated above. To this
%end, one of our current research efforts is the development of a CP
%model exploiting the propositions proved in this paper
%%%%%%%%%%%%%%
\section{Conclusion} \label{sec:conclusion}

In this paper, we addressed an existing parallel-batch scheduling
problem for which the current state-of-the-art approach is constraint
programming. Inspired by the conception of moves from a canonical
solution, we proved a number of propositions about the problem, allowing
us to create a novel MIP model that, after presolving, is less than
half the size of the previous MIP model. Empirical results demonstrated
that, primarily due to the ability to find
good feasible solutions quickly, the new MIP model was able to out-perform the
existing CP approach over a broad range of problem instances both in
terms of finding and proving optimality and in terms of finding high
quality solutions when the optimal solution could not be proved.

\bibliographystyle{splncs}
\bibliography{bibliography}


\end{document}
