\documentclass[13pt, letterpaper, oneside]{book}
\usepackage{graphicx}

\usepackage[driver=xetex,paperwidth=8.5in,paperheight=11in,left=1.4in,
right=1in,top=1.3in, bottom=1.4in]{geometry}
\usepackage[no-math]{fontspec}
\usepackage{newfloat}
\usepackage{sectsty, tikz, color, pgfplots}
\usetikzlibrary{shapes,arrows}
\usepackage{multicol}
\usepackage{amsmath, amssymb, amsfonts,  titlesec}
\usepackage[urw-garamond,cal=cmcal]{mathdesign}
\usepackage{fancyhdr, booktabs, longtable}
%\usepackage[font=small,format=plain,labelfont=it,textfont=it]{caption}
\usepackage{caption,subcaption}
\usepackage{listings}
\usepackage{algpseudocode, algorithm,setspace}
% \usepackage[T1]{fontenc} 
\usepackage{enumitem,verbatim,natbib}

 \DeclareTextCommandDefault{\nobreakspace}{\leavevmode\nobreak\ } 
\include{typography}

\usepackage[hidelinks]{hyperref}

\begin{document}
\frontmatter

\include{coverpage_cardboard}
\pagebreak
\include{coverpage}
% abstract
% acknowledgements

%\include{firstpage}

\tableofcontents
\listoffigures
\listoftables

\pagestyle{fancy}
\mainmatter
\pagebreak
\vskip 4em
\fontsize{12pt}{17pt}\selectfont
\chapter{Introduction}
This paper discusses three different approaches, and several variations on them,
to solving the problem of scheduling non-identical jobs on a batch processing
machine. Batch processing machines, for the purposes of this paper, can process
multiple, non-identical jobs simultaneously---but all jobs must be loaded into
and unloaded from the machine at once, which introduces a considerable twist on
the ``simple parallel resources'' known from typical example problems in
existing literature.

The machines in question represents real-life resources like autoclaves or
ovens, which can process multiple items at a time, but often cannot be opened at
random---in fact, such machines often need to wait for the largest item in the
batch to be done before the next batch can be inserted.

\citet{Malapert} proposed a global constraint programming algorithm consisting
of a set of filtering rules to solve the problem. He achieved considerably
better speeds than with a simple mixed-integer model, but it seems plausible
that the new global constraint is unnecessarily cumbersome to achieve this
performance; simple MIP, CP or decomposition approaches are easier to implement
and extend.  In this paper, we present 1) an improvement to his MIP model, 2) a
CP model and 3) a decomposition approach to ``divide and conquer'' the problem.

\section{Problem definition}
We describe the problem as follows: assume we are given a set of jobs $J$, each of
which has a processing time (or ``length'') $p_j$ and a size (or ``capacity
requirement'') $s_j$. Each job also
has a due date $d_j$. The machine is characterized by its capacity $b$, and in
every batch, the jobs' summed sizes must not exceed this number. All values are
integer.

The machine can only process one batch $k$ of jobs at a time, and batches always
take as long as the longest job in the batch (i.e. $P_k = \max_{j \in k}(p_j)$).
Our objective is to minimize the lateness $L$ of the latest job in $J$, where
$L$ is the difference between the job's completion time $C_j$ and its due date
$d_j$---in formal terms, \textit{min.} $\Lmax = \max_j(C_j - d_j)$. The job's
completion time, however, is the completion time of the batch, which in turn
finishes with its \textit{longest} job as stated above.

Malapert uses the standard format established by Graham et al. to
summarize the problem as $1|\textit{p-batch}; b < n;
\textit{non-identical}|\Lmax$, where $\textit{p-batch};b<n$ represents the
parallel-batch nature and the finite capacity of the resource. A simpler version
with identical job sizes was shown to be strongly NP-hard in \citep{Brucker};
this problem, then, is no less difficult.

It helps to visualize the jobs before delving into the technicalities of
scheduling them. Figure \ref{fig:intro_tetris} shows a solution to a sample
problem with eight jobs and a resource with capacity $b = 20$.

\input{figures/intro_tetris.tex}
\section{Organization of this paper}
After reviewing some of the most relevant publications on both general MIP/CP models and
batch scheduling problems, we first describe Malapert's original MIP model in
section \ref{sec:malapertmipmodel}. We then present possible improvements to the
model in \ref{sec:improvedmipmodel}. Section \ref{sec:cpmodel} introduces a CP formulation of the same
problem. Sections \ref{sec:mipdecomp} and \ref{sec:cpdecomp} describe a
decomposition approach.

An empirical comparison of the new models and a discussion of the results follow in
sections \ref{sec:results} and \ref{sec:discussion}. Ideas for future work are
listed in \ref{sec:futurework}.

\chapter{Background}
% citet{Azizoglu} results in [2002]
% citep{Azizoglu} results in [Azizoglu et al., 2002]
% citep*{Azizoglu} results in [Azizoglu and Miller, 2002]
Many optimization problems, and scheduling problems in particular, are
combinatorial in nature. The number of possible solutions grows exponentially
with the number of input variables, and even with fast computers it is
impossible to explore all of them individually to find the best one
(also called ``full enumeration'', or ``brute-force'' search) in a reasonable
amount of time. Often, however, it is possible to reason about subsets of
solutions that are known to be suboptimal a priori. This limits the search
space, allowing us to solve many instances of difficult combinatorial problems
in few hours, minutes or even seconds.

Such constrained searches are often implemented in either of two ways (or
variants of them): as a \textit{Constraint Programming model} (CP) or as a
\textit{Mixed Integer Programming model} (MIP). In this section I will briefly
introduce the concepts behind both CP and MIP and review recent work on problems
similar to the one dealt with here.

\section{Constraint Programming}
A constraint program specifies relationships, \textit{constraints}, that must
hold between input variables in the form of mathematical equations or
inequalities. Every input variable is assigned a set $\mathcal{D}$ of potential
values it can assume, its \textit{domain}. The solving algorithm begins by
assigning a value to one of the variables. Using the constraints, the solver can
then often reduce the other variables' domains, i.e. eliminate other potential
values of other variables. These domain reductions may themselves trigger domain
reductions in other variables, and so on, in a process called
\textit{propagation}. Propagation can lead to one of three results:
\begin{alist}
\item{an inconsistency, in which a variable's domain is reduced to an empty set.
That is, the given constraints allow for none of that variable's
potential values given the values assigned to other variables. As a result, the
solver will \textit{backtrack}, i.e. undo one or more of previous assignments
made, and assign other values.}
\item{a consistent solution, in which every variable's domain is reduced to a single value
(a singleton). If we are searching for an optimal solution, this may replace an
incumbent solution if it is better.}
\item{some reduced domains, but neither a solution nor an inconsistency. In this
case, the solver assigns more values to variables to trigger more propagation,
until a solution or an inconsistency is reached.}
\end{alist}

Without formally introducing different notions of inconsistency, it should be
noted that a problem can have no solution even when all variables have
non-empty domains. (See figure).

Unlike in MIP, constraints in CP are not restricted to expressions that are
linear in the input variables. Furthermore, so-called \textit{global
constraints} can be used that act on entire sets of variables at once. They are
implemented as custom algorithms that rely on specific knowledge about the
problem and are often based on results from graph theory. Global constraints can
be powerful tools; a classic example is the \texttt{alldifferent} constraint
which ensures that a set of variables take on unique values. While a number of
not-equal relationships between the variables can achieve the same effect after
several propagations, the global constraint reduces the domains of all involved
variables in one fell swoop such that for each variable, only the values remain
that are consistent with those of all the other variables.

\section{Mixed Integer Programming}
\subsection{Linear Programming}
Mixed Integer Programs (or ``MIP
models'') express the minimization of a linear function subject to linear
constraints. If all variables in the problem can be rational in the solution,
the MIP model is really a \textit{linear program} (LP), which can be solved in
polynomial time.\footnote{In practice, variations on Dantzig's \textit{simplex
method} are most often used to solve LPs. Such solvers perform very well on most
problems, but no known variant has been proven to have polynomial worst-case
complexity \citep{papadimitriou}. Solvers with theoretically polynomial-time
complexity exist (Karmarkar's algorithm \citet{karmarkar} has a runtime of
$\mathcal{O}(n^{3.5}L^2 \cdot \log L \cdot \log \log L)$, for instance, where
$L$ is the number of bits of input), but are used less frequently.}

Figure
\input{figures/lpplot1}
\ref{fig:lpplot1} illustrates the concept of an LP in two variables, $x_1$ and
$x_2$, as listed in model \ref{lpintro_model}. The set of feasible solutions is given by the shaded area bounded by the axes
and by three inequalities (``constraints''). A third linear term, the objective
function $3x_1 + x_2$, is to be maximized.\footnote{Minimization is more common,
but note that multiplying the objective by $-1$ achieves this.} 
\begin{model}
\begin{alignat}{2}
\text{Maximize}\quad & 3x_1 + x_2 && \\
\text{subject to the constraints}\quad & -x_1 + 3x_2 \leq 12 &&\\
& x_1 + 9x_2 \leq 67 && \\
& 2x_1 - x_2 \leq 6 && \\
& x_1 \geq 0 && \\
& x_2 \geq 0 && 
\end{alignat}
\caption{A simple LP model, as shown in figure \ref{fig:lpplot1}}
\label{lpintro_model}
\end{model}

Although the objective function is shown in the figure as a line in a specific
location, note that, as it is not an equation, it can be represented by any line
parallel to that shown in the figure. While we are trying to maximize the
objective value, the solution must be feasible. It is thus obvious
that the desired extreme value of our objective function is found at one of the
``corners'' of the shaded area: the solution is marked $\otimes$ in the figure.
In fact, since the shaded area generated by linear inequalities will always be a
convex polygon (or polyhedron, in higher dimensions), the solution will
invariably be found at an intersection of hyperplanes.

\subsection{Solving MIP models using branch-and-bound}
MIP models are LPs in which some of the decision variables are declared
integers---thus their name.  Like LP models, MIP models also require an
objection function to be minimized. Figure
\input{figures/mipplot1}
\ref{fig:mipplot1} illustrates this based on the LP problem above: now, only the
black dots represent feasible solutions. While the solution is easily found in
the figure by inspection (simply round to the nearest feasible integral
solution!), this is not the case in problems with many variables; it is
difficult enough to visualize the problem in three dimensions, and many problems
require hundreds or thousands. Moreover, rounding is particuarly unreliable 
with variables of small domains (e.g. binary variables), which are often used in
MIP models to represent decisions. Indeed, solving MIP models is NP-hard.

Similar to CP searches, MIP searches can be thought of as trees, where every
branch represents an assignment of a value to a domain and every leaf represents
a feasible solution. The difference lies in the way MIP explores this search tree.

The MIP solver first solves the problem as an LP, which will usually result in
fractional values for all or most of the variables. In this context, the LP is
known as the \textit{LP relaxation} of the problem---an easier, approximate
version of the original. Assuming we are minimizing the objective, the resulting
LP objective value will be a lower bound on the optimal MIP objective value.
At this point, the solution is $x_1 = 4.6, x_2 = 3.2$.

The solver then chooses a variable, based on heuristics, and \textit{branches}
on it. In this case, assume that we branch on $x_2$, which means that we set
$x_2 \leq 3.0 \lor x_2 \leq 4.0$. We now have two new MIPs, as shown in figure
\ref{fig:mipplot2}.\input{figures/mipplot2}

In this case, the optimal value for $x_2$ was within $\pm1$ of its LP value.
This is often the case, and 



. The current solution from
the LP relaxation is fractional and thus infeasible. The search tree 

which generally results in fractional values for most variables, such as $x =
a$. It then branches on possible values for $x$: either $x < a$ or $x > a$. If
$a$ is integral, $x = a$.  The MIP solution at a node $n$ also serves as a
\textit{lower bound} $LB_n$ on solutions in the respective subtrees: once a
solution with an objective value of $v$ is found, $v$ becomes an \textit{upper
bound} on the optimal objective value and all yet unexplored subtrees with $LB_n
\geq v$ need no longer be searched (``pruning'' the subtree). This procedure is
called \textit{branch-and-bound} and the most basic method used to solve integer
programming problems. Other methods exist, e.g. \textit{branch-and-cut}, and are
often used in conjunction with branch-and-bound in today's solvers.

\section{Literature}
The problem at hand is based on the work of \citet{Malapert}, who proposed a global
constraint \texttt{sequenceEDD} to be used in combination with \texttt{pack} to
solve it to optimality. The \texttt{sequenceEDD} constraint is implemented as
four distinct filtering rules applied at relevant domain changes: three to update
bounds on $\Lmax$ based on different conditions, and one to limit the number of
batches based on the marginal cost difference between adding a job to an empty batch vs. an
existing one. The new global was shown to significantly outperform a simple MIP model of the same problem.

Other authors have examined similar problems: \citet{Azizoglu} provide an exact
method and a heuristic for the same problem, but minimize makespan
($C_\text{max}$) instead of $\Lmax$, as have \cite{Dupont}. Similar exact
methods have been proposed for multi-agent variants with different objective
functions \citep{Sabouni}, for makespan minimization on single batch machines
\citep{Kashan}, and for makespan minimization on parallel batch machines with
different release dates \citep{Ozturk}. A more extensive review of MIP model
applications in batch processing is given by \citet{Grossmann}.

\chapter{Modelling the problem}

\input{mipmodel.tex}

\input{cpmodel.tex}
\input{decomp.tex}

\input{testresults.tex}
\input{discussion.tex}
\input{futurework.tex}
\input{mip2model.tex}

\begin{comment}
\chapter{My solution}
\section{MIP formulation improvements}
\section{CP formulation improvements}

\chapter{Discussion}


\end{comment}
\pagebreak

\bibliographystyle{plainnat}
\bibliography{bibliography}{}
\vskip 4em
\appendix
\chapter{Appendix: Tables}
\section{Hello. This is the first part of the first Appendix}
Blabla.

\chapter{Appendix: Code}
\backmatter
\end{document}

