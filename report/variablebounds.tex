\section{Bounds on variables known a priori}

\subsection[Lower bound on $\Lmax$]{Lower bound on {\sansitalicfont L}\textsubscript{max}}
A lower bound on $\Lmax$ can be found using the lower bound on the completion
date of each bucket $q$, where a bucket is defined as the set of batches with
due date $\delta_q$:
\begin{alignat}{2}
& \Lmax \geq C_{\text{max},q} - \delta_q \quad && \forall q
\end{alignat}
This works because the buckets up to bucket $q$ are guaranteed to contain all
jobs with due dates $d \leq \delta_q$, since the batches within the buckets are
ordered by earliest due date (EDD) in the optimal solution. The buckets up to
bucket $q$ will likely also contain some later ($d > \delta_q$) jobs in the
optimal solution but this does not affect the validity of the lower bound.

%To find a lower bound on $C_{\text{max},q}$, we can exploit the fact that every
%batch needs to span its jobs. If we order the jobs up to bucket $q$ by non-increasing processing
%time $p$, then we can use algorithm \ref{alg:findcmax} to find
%$C_{\text{max},q}$:
%\begin{algorithm}
%\begin{algorithmic}
%\State $J^{\star} \gets J$ \Comment{initialize all jobs as unassigned jobs}
%\State $n_k \gets 1$; $S_k \gets \{0\}$; $P_k \gets \{0\}$ \Comment{Create one
%empty batch of size and length zero}
%\State sort $J^{\star}$ by processing time, non-increasing
%\Repeat
%  \State $j \gets J^{\star}$.pop() \Comment{select job for assignment, longest job
%first}
%  \Loop $\;$ through all $n_k$ existing batches $k$, first batch first
%    \State $k_p \gets \emptyset$ \Comment{no feasible batch}
%    \State $c_\text{min} = b$ \Comment{currently known minimum remaining
%    capacity}
%    \If{$s_j < b-S_k$ and $b-S_k < c_\text{min}$}
%      \State $k_p \gets k_p$; $c_\text{min} \gets b-S_k$
%    \EndIf
%  \EndLoop
%  \If{$|k_p| = 1$}
%      \State $S_{k_p} \gets S_{k_p} + s_j$ \Comment{assign job $j$ to batch $k_p$}
%  \Else
%    \State $n_k \gets n_k + 1$\Comment{open new batch}
%    \State $S_{n_k} \gets s_j$; $P_{n_k} \gets p_j$ \Comment{assign $s_j$ and $p_j$ to the new batch}
%  \EndIf
%\Until{$J^{\star}$ is empty}
%\end{algorithmic}
%\caption{Finding $C_{\text{max},q}$}
%\label{alg:findcmax}
%\end{algorithm}
%
%The algorithm is based on the following reasoning: no matter the assignment, one
%batch will have the length $P_k$ of the longest job $\max(p_j)$.
%Since we ordered and assigned the jobs by $p_j$, this will be the first batch
%$k_1$.
%Continue filling $k_1$ until some job $j_c$ exceeds capacity. This job
%must go into another batch $k_2$. Swapping $j_l$ with any of the already assigned jobs
%in $k_1$ (capacity allowing) increases $C_\text{max}$. Even if ``leaving
%capacity'' in $k_1$ for later, better-fitting open jobs may seem desirable --
%these other open jobs will necessarily be shorter than $j_c$, so such a move
%will again serve to increase $C_\text{max}$. Open jobs that fit into
%previous batches with some remaining capacity should be assigned to the batch
%with the \textit{minimum} feasible remaining capacity $c_\text{min}$. This
%avoids unnecessarily precluding shorter (still open) but slightly larger jobs
%from being assigned to previous batches wherever possible. 
%
%A combination of shorter jobs may be a better fit to a previous batch than a
%single, longer job in terms of using remaining capacity, but what matters is
%only the processing time.
%

Now we need to find $C_{\text{max},q}$, or at least a lower bound on it, in
polynomial time. The simplest approach simply considers the ``total elastic area'',
i.e. the sum of all $s_j p_j$ products:
\begin{alignat}{2}
& C_{\text{max},q} \geq \big\lceil\frac{1}{b} \sum_{j} s_j
p_j\big\rceil \quad
&& \forall q, \forall \{ j \in J | d_j \leq \delta_q \}
\end{alignat}
A better lower bound on $C_{\text{max},q}$ would be given by a
preemptive-cumulative schedule. Unfortunately, minimizing $C_{\text{max}}$ for
such problems is equivalent to solving a standard bin-packing problem, which
requires exponential time. 

\subsection[Upper bound on $\Lmax$]{Upper bound on {\sansitalicfont L}\textsubscript{max}}
An upper bound on $\Lmax$ can be found by using a dispatch rule to find a
feasible, if not optimal, schedule. A good approach could be the ``best-fit''
heuristic proposed in the original paper. {\color{darkred} This has not been
implemented yet.}

\subsection[Bounding the number of batches $n_k$]{Bounding the number of batches \sansitalicfont n\textsubscript{k}}
Initially, the number of batches needed is assumed to be equal to the number of
jobs: $n_k = n_j$. Reducing $n_k$ by pre-computing the maximum number of batches
needed shrinks the $x_{jk}$ matrix, and prunes potential search branches in
branch-and-bound decomposition approaches.

\input{figures/bnk1_1050}

Unfortunately, we cannot make a general statement that optimal solutions never have more batches than other feasible solutions -- a simple counterexample is shown in figure \ref{fig:bnk1}.\footnote{To be more precise, we cannot state that at least one optimal solution is in the subset of feasible solutions that uses the fewest number of batches -- a dominance situation that could be exploited, were it true.}

Starting out with a one-job-per-batch schedule sorted by EDD, we can explore
all feasible batch configurations recursively. To generate any other feasible
schedule (including the optimal solution), jobs $j$ are rescheduled (``moved back'')
from their original batch $k_\text{origin}$ into a prior batch
$k_\text{earlier}$. This eliminates $k_\text{origin}$ and requires, of course,
that $k_\text{earlier}$ has sufficient capacity. If the job's processing time
$p_j$ exceeds that of $k_\text{earlier}$, then the lateness of batches between
$k_\text{earlier}$ and $k_\text{origin}$ will increase; the merit of such a move
cannot be judged in prior, so it is an \textit{unsafe} batch elimination.
\textit{Safe} eliminations, on the other hand, will never worsen $\Lmax$, and
only they can be considered when bounding $n_k$ a priori.

Algorithm \ref{alg:bounding_nk} outlines a recursive method to find an upper
bound on $n_k$, recognizing safe batch eliminations only.

\begin{algorithm}[h]
\fontsize{9pt}{11.5pt}\selectfont
\begin{algorithmic}
\If{no open jobs left} \Comment{if this is a ``leaf node'' in the recursion}
  \State update UB$(n_k)$
\EndIf
\State find the combination of unsafe later jobs that fills up the capacity
most, leaving us with capacity $b_r$ 
\State find all combinations $x$ of safe later jobs that fit into $b_r$
\Repeat
  \State $x$ = next safe job combination
  \State \textit{ignoreJobs} $\gets x$ \Comment{make the moves, let the next recursion
  level deal with the rest of the jobs}
  \State spawn and run child node with $J \setminus$ \textit{ignoreJobs}
  \State \textit{ignoreJobs} $\gets$ \textit{ignoreJobs} $\setminus x$
\Until{all combinations have been explored}
\State return
\end{algorithmic}
\caption{Recursive algorithm to find an upper bound on $n_k$}
\label{alg:bounding_nk}
\end{algorithm}

This algorithm evidently requires exponential time. A relaxed variant is a
possible option: if only a single unsafe move \textit{into} a batch is possible,
no safe eliminations into that batch are considered at all and we skip to the
next batch. This would greatly speed up the recursion but also significantly
weaken the usefulness of the resulting upper bound.

In a brach-and-bound decomposition approach in which batches are modelled
individually, an upper bound on $n_k$ could be used to limit the depth of the
search tree, or, in combination with a method to determine a lower bound on the
remaining jobs' $n_k$ at every node, to actively prune the search tree during
the search. The latter method, however, would also run in exponential time as
it, again, would require knapsack-type reasoning unless we use a much less powerful
relaxation.

%It is perhaps possible, however, to generate a feasible solution that is likely to use $n_k < n_j$ and to guarantee that such a solution will never use fewer batches than the optimal solution. To do this, let the initial solution $\pi_0$ be a schedule in which every job is assigned to one batch (i.e. $n_k = n_j$) and the jobs are ordered by non-decreasing due date (i.e. $d_n \leq d_{n+1}$), as in figure \ref{fig:bnk2}.
%
%\input{figure showing all the jobs in EDD sequence}
%
%Capacity permitting, jobs are now moved into earlier batches to improve the schedule, eliminating the batch they were placed in initially. Every such move reduces $n_k$ by one.
%
%Two types of moves are possible: \textit{safe} moves and \textit{risky} moves. A move is safe when a job is moved into an earlier batch of longer processing time. A move is risky when a job is moved into an earlier batch of shorter processing time, thus increasing the lateness of that batch.
%
%Moving a job has three effects: 
%
%\begin{alist}
%\item{Effect on the batches after}
%\item{Effect on the batches between, including the new job}
%\item{Effect on the job itself}
%\end{alist}
%
%\begin{table}
%\centering
%\begin{tabular}{r c c}
%\toprule
%              & safe                 & risky \\
%\midrule
%batches after & lateness improves by $p_j$ & lateness improves by $p_a$ \\
%batches between & --- & lateness worsens by $p_j - p_a$ \\
%job itself & lateness improves & lateness improves\\ 
%\bottomrule
%\end{tabular}
%\caption{Lateness effects of safe and risky moves}
%\end{table}
%
%We can easily generate a solution that only contains safe moves.
%We now need to prove that our relaxed solution $\pi_{\text{edd}}$ will never use fewer batches than the optimal solution $\pi_{\text{opt}}$.
%
%For this to be true, we need to show that if there is ever a situation in which we could \textit{either} make $n$ unsafe moves \textit{or} $m>n$ safe ones, using the unsafe ones will never be beneficial if the remaining $m-n$ safe candidates cannot be moved somewhere else.
%
%We're trying to find a relaxation of the problem that is guaranteed to generate as least as many batches as the optimal solution.
%
%
%Whenever there is an alternative between $n$ unsafe moves and $>n$ safe ones, perform $n$ safe ones. Whenever only an unsafe is available, eliminate none and proceed to the next batch.
%
%Unfortunately, we cannot generally state that optimal solutions never have more batches than other feasible solutions: when a job $j_b$ is moved into a prior batch holding $j_a$ and $d_b > d_a$ as well as $p_a < p_b$, it can sometimes happen that $\Lmax$ is increased.
%
%\subsubsection{Some stuff to try}
%
%We can try only considering jobs \textit{before} $\Lmax$, because anything after that job wouldn't be moved in an optimal solution. 
%
%

\begin{comment}
Certain things:
\begin{alist}
\item{When a safe and an unsafe host are available, and we are the last guest,
and the safe host is before the unsafe one, always choose the safe host. (Is this
only true for the last guest?)}
\item{Not moving a job back means it must become a host itself.}
\end{alist}

Open questions: 
\begin{alist}
\item{A job's lateness can only worsen by $p_j$ at a time. Thus, performing safe
elimination on any $\Lmax$ job will make the new host the new $\Lmax$. Is this
true? What implication does that have on what the final schedule looks like?}

\end{alist}
\end{comment}
